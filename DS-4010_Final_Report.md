## Introduction
Recidivism is the tendency of formerly incarcerated individuals to reoffend and return to prison. This is a critical issue in the U.S. justice system and understanding what factors influence recidivism rates can help policymakers and the public make more informed decisions about social programs and resource allocation. In this project, we sought to analyze the relationships between recidivism rates and various demographic, economic, and crime-related factors across the United States. By combining data from the FBI Crime Data Explorer and the U.S. census, we created a dataset and constructed a predictive model. Our goals were to determine which factors correlate most strongly with recidivism and to build an interactive Power BI dashboard that enables users to explore this information visually. The dashboard serves as a public learning tool and highlights how data can be used to better understand social outcomes.
## Data Pipeline
### Data Collection (ETL)
We gathered our data from various sources. Our main point of interest was recidivism rate which came from the FBI CDE(crime data explorer). This data was available using a free api. The rest of our data was just manually downloaded and added to our repository. The links to the sites where our data came from are all in the repository. The data from the fbi api came down in json format, so it was an interesting challenge to work with that. We ended up using the sqlite3 python library in order to have an integrated database in our repository. All of the data was loaded into this database which allowed us to parse the json, perform calculations, and do any transformations necessary using sql scripts. In order to interact with the database we created a system of commands to run predefined functions. This included functions that created tables from csv files, automatically using headers to create column names. We also had a custom function for loading in the state data from the fbi api. Since this data came down as individual files for each state we had a loop loading each state into a staging table. In the staging table the json is parsed and put into columns. Each state is then inserted into the actual table. Once all of the data from the csv and json files are loaded into their own tables we combine them all into one final table. Another interesting concept we used is called a utility table. This is a table that contains keys to join other tables together. Our utility table contained state names with their abbreviations in order to join data from different sources that didn’t all use the same names. Next we had a function for getting the data back out of the final table and writing it to a csv. This is what we then used for our modelling and dashboard. Some benefits of using the integrated database were that it made it easy to add more data. If we had a new file we could simply add it to the list of functions to load it into a table and modify the sql script to retrieve the columns we wanted from that table. It also made it easy to create new columns by performing basic calculations on the data. One example of this was getting population density using the size of a state and population. We were also able to calculate what percentage of the prison population was made up of various demographic groups and what percent of crimes were violent. In order to keep our code organized we created some classes to handle specific tasks. These are in the connectors folder. There is a database class that can execute sql to perform any interactions with the database. There is also an extractor class that is used for extracting data from urls or reading in data from files. We organized our functions into different modules based on what they did. The first module was execution which included the function to take in commands and execute other functions. This is what is called by our main.py file. Then we had an extraction module which just included functions for downloading files. The transformation module was used for loading data into our database and executing sql. It includes all of our sql code in a resources folder. We have a data folder that contains all of our data. Rawdata includes any manually downloaded files. The working folder is created to hold any data while it is being processed. The output folder is where files are placed after being extracted from the database. We then created a modelling folder which does not have any automation. Any files used there should be manually moved. The modelling folder uses jupyter notebooks since these are easy to use for working with data. We used dynaconf and a toml file to store our api keys locally. This is a common library used for loading config files and makes it easy to have private keys by creating a secrets file that is included in the .gitignore. 
### Modelling
The purpose of the dashboard is to explore how the recidivism rate is influenced by various demographic and economic factors. For this study, we investigated several models, such as logistic regression, decision trees, random forest, boosting, and linear regression, to forecast recidivism rates based on economic and demographic data. With R2 ratings close to or below zero, the majority of models, however, did not perform well on the test data, suggesting inadequate predictive potential. Although it was still modest, the best-performing model was a straightforward linear regression using the percentage of men under the age of 18 as the predictor (R2 = 0.009). Because Lasso regression offered both feature selection advantages and the lowest test Mean Squared Error, we finally decided to utilize it as our final model. Our objective of comprehending the elements driving recidivism was effectively served by Lasso's use of L1 regularization, which reduces less significant coefficients to zero and highlights the most instructive aspects.

The model was implemented using Python in VS Code, using packages such as pandas, scikit-learn, and numpy. After cleaning and transforming the data, we trained the Lasso model on standardized inputs. The model used in this project was pre-estimated, not created or retrained in real-time. We trained the Lasso regression model offline using Python and stored the resulting predicted recidivism rates and model coefficients in CSV files. These files were then imported into Power BI for visualization and user interaction. Although the dashboard allows users to adjust inputs such as population density, percent Native American, percent Black, and quality of life score using sliders, these changes do not trigger real-time model retraining. Instead, Power BI uses the stored regression coefficients to recalculate a predicted recidivism rate based on the user’s selected input values. This approach enables interactive exploration without requiring dynamic computation, which Power BI(especially the free version) does not support natively.    


### Dashboard
The dashboard was built using Power BI for visualization and Python scripts to pull data from the model and save it into CSV files. These CSVs were imported into Power BI to create visuals. The dashboard itself is divided into multiple pages, each designed to focus on a different aspect of the data. It starts off on an “About” page, which states the purpose, what the data is about, and describes our model. Then the “Recidivism Rate and Crime Demographics” page followed by the page “Age Demographics”. Additional pages break down other key areas, such model predictions and a drill through page. 

This layout was chosen to support the project’s goal of exploring crime trends and demographic factors across the United States without overwhelming the user. By focusing on certain topics on individual pages, users can focus more clearly on particular themes. The drill through functionality, which allows users to right click on a state on the map and see detailed information enhances user exploration while keeping the main pages uncluttered. The pages are not linked together, changes made on one page do not affect the others, aside from the drillthrough action. The drillthrough page is titled “State Information” which shows the name of the state that you chose, along with three main text cards highlighting certain variables, and graphs.

User inputs are a key feature of the dashboard. Inputs include numeric sliders for adjusting variables like “Quality of Life Score” and “Population Density”. Categorical dropdown menus for selecting states and gender, and drillthrough actions for selecting specific states for deeper analysis. These inputs supported the project goals by allowing the users to dynamically explore relationships between demographic or economic factors and crime rates. Input types varied across numeric ranges, single selections, and multiple selections depending on the visualization.

The outputs shown to the users were a combination of figures such as maps, pie charts, and bar graphs. Text based metric cards for displaying key statistics like “Average Recidivism Rate”, “Imprisonment Rate” and “Quality of Life Score”. Maps based on different rates, where each state on the map determines where the state lands on the variables range based on color, red for a high rate and green for low. Bar charts showing different distributions and counts of the variable. Finally pie charts which organize and show the data as a percentage of a whole.

Power BI was the main technology used to construct the dashboard. It proved generally easy to use for visualization building, particularly features like drag-and-drop creation, formulas, and drill through pages. However, there were limitations because Power BI Desktop is not available on MacOS, preventing half the team from fully participating. Collaboration was also hindered by the limitations of free Power BI Pro accounts, which restrict publishing and sharing options. 

Subjectively, Power BI offered good features and decent speed for the size of the data we were working with, but challenges around collaboration, Mac compatibility, and dynamic integration with Python were some challenges. Overall, while the dashboard provided an effective and interactive way to explore the data, both technical and model related issues constrained some aspects of the project.
## Application
### Results
We were able to create a dashboard that achieves our goals for this project. Our dashboard allows users to explore crime information for the states in our data. Users can look at variables like the recidivism rate, imprisonment rate, quality of life score, and explore the ethnic and gender demographics of the prison population. Our model offers an interactive way for users to see how other variables affect recidivism rates.
## Discussion
### Next Steps
If we had more time to continue with this project, our team would look for more data to add to our dataset so we can improve our model. While working on creating a model, we found that many of the variables in our dataset, like types of crimes and some of the demographic information, were not significant variables in predicting recidivism rate. Although we were able to create a functional model with the existing data, its performance could be significantly improved by adding more relevant and high-quality data.

Another area we would have explored further is the capabilities of Power BI. The constraints of the free version limited our use, but with more time, we could have better researched its full potential. For instance, while Power BI Pro offers built-in options for integrating machine learning models into reports, we had to work around this limitation by exporting our model’s output to a CSV file for use in the dashboard. Given more time, we could have investigated ways to incorporate the model directly into the report using available features. Additionally, we faced limitations in sharing our work, although the free version supports embedding reports into publicly accessible websites, we didn’t have the opportunity to explore this functionality.
### Availability
The links to our datasets and code can be found in our team's GitHub repository. We do not plan to maintain our code after this project. We plan to keep our repository public so other classes can view it. A copy of our Power BI file can also be downloaded and opened locally in the Power BI Desktop app. 
### Conclusion

Despite the limitations of our predictive model, we were still able to achieve our primary goal to provide an accessible exploration of recidivism and its possible influences. Through extensive data transformation, cleaning, and visualization, we created a Power BI dashboard that allows users to interact with key demographic and economic variables and examine their potential relationships with recidivism rates. Our use of Lasso regression, though not highly predictive, still offered insights to which features were most relevant. We came across many technical challenges with Power BI’s limited sharing capabilities and license constraints, and in the future would like to spend more time finding ways to work around these limitations. Ultimately, this project reinforces the value of combining statistical modeling and interactive visualizations to communicate complex social issues in a way that is both informative and engaging.
